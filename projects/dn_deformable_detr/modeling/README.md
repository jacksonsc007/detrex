# major version 1
## minor version 1.0
1. only use matching queries to generate cross-attention-weight map
2. extend the original reference points for encoder to reference boxes.
3. make use of attention weight threshold to identify background tokens which have tenuous, if any, links to objects. Their refence points remain as it own position.
4. tokens having potential objects use their corresponding box predictions as their new reference boxes.

## minor version 1.1
based on v1.0, we add:
1. only matching queries with cls > 0.2 contribute to the cross-attention map.


## minor version 1.2
To modify the generation of sampling offsets and attention weight.

For the encoder in the original works, both sampling offsets and attention weights are generated by token features itself. We suspect that tokens are not capable of identifying meaningful sampling locations, so we decide to make some changes:

### 1.2.0
1. We'd like tokens focus on meaningful keypoints of objects, which are identified by object queries themselves. Subsequently, the sampling offsets are generated by corresponding object queries. 

- TODO
2. The generation of attention weight comes in two ways:
- naive scaled dot-product between feature of tokens and sampling points.
- object queries decide the attention weights for each sampling points.